{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from CoNLL-U to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse\n",
    "import pprint\n",
    "import json\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Function conllu_to_dict parse conllu file using conllu library and returns in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conllu_to_dict(filename, num_sents=999999):\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        conllu = f.read()\n",
    "\n",
    "    # Metadata of treebank documents\n",
    "    document = {\n",
    "        \"_id\": file[10:-7],\n",
    "        \"dir\": file[10:-7].split('\\\\')\n",
    "    }\n",
    "    parsed = parse(conllu) # Use conllu library to parse conllu file\n",
    "    \n",
    "    sentences = []\n",
    "    sent_size = min([len(parsed), num_sents]) # replace with len(parsed) to store all sentences\n",
    "    \n",
    "    for i in range(sent_size):\n",
    "\n",
    "        sent = {\n",
    "            \"metadata\": {\n",
    "                **dict(parsed[i].metadata),\n",
    "                \"flag\": random.randrange(0,3,1) #insert random int between 0 and 3, replace function as needed\n",
    "            },\n",
    "            \"token\": json.loads(json.dumps(parsed[i]))\n",
    "        }\n",
    "        sentences.append(sent)\n",
    "        print(\"sentences parsed\", i+1, end=\"\\r\")\n",
    "        \n",
    "    document[\"sentences\"] = sentences\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get list of CoNLL-U files and parse it into JSON\n",
    "`doc = conllu_to_dict(file, 20)` converts 20 sentences from each document\n",
    "<br>\n",
    "`doc = conllu_to_dict(file)` converts all sentences from each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed document:  UD_Afrikaans-AfriBooms\\af_afribooms-ud-dev \n",
      " Number of sentences parsed:  194\n",
      "Parsed document:  UD_Afrikaans-AfriBooms\\af_afribooms-ud-test \n",
      " Number of sentences parsed:  300\n",
      "Parsed document:  UD_Afrikaans-AfriBooms\\af_afribooms-ud-train \n",
      " Number of sentences parsed:  300\n",
      "Parsed document:  UD_English-GUM\\en_gum-ud-dev \n",
      " Number of sentences parsed:  149\n",
      "Parsed document:  UD_English-GUM\\en_gum-ud-test \n",
      " Number of sentences parsed:  300\n",
      "Parsed document:  UD_English-GUM\\en_gum-ud-train \n",
      " Number of sentences parsed:  300\n",
      "Parsed document:  UD_Hindi-HDTB\\hi_hdtb-ud-dev \n",
      " Number of sentences parsed:  69\n",
      "Parsed document:  UD_Hindi-HDTB\\hi_hdtb-ud-test \n",
      " Number of sentences parsed:  300\n",
      "Parsed document:  UD_Hindi-HDTB\\hi_hdtb-ud-train \n",
      " Number of sentences parsed:  300\n",
      "Parsed document:  UD_Tamil-TTB\\ta_ttb-ud-dev \n",
      " Number of sentences parsed:  80\n",
      "Parsed document:  UD_Tamil-TTB\\ta_ttb-ud-test \n",
      " Number of sentences parsed:  120\n",
      "Parsed document:  UD_Tamil-TTB\\ta_ttb-ud-train \n",
      " Number of sentences parsed:  300\n",
      "Parsed document:  UD_Telugu-MTG\\te_mtg-ud-dev \n",
      " Number of sentences parsed:  131\n",
      "Parsed document:  UD_Telugu-MTG\\te_mtg-ud-test \n",
      " Number of sentences parsed:  146\n",
      "Parsed document:  UD_Telugu-MTG\\te_mtg-ud-train \n",
      " Number of sentences parsed:  300\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"treebanks/**/*.conllu\", recursive=True) \n",
    "docs = []\n",
    "for i, file in enumerate(files):\n",
    "    print(i, \"/\" , len(files), end=\"\\r\")\n",
    "    \n",
    "    doc = conllu_to_dict(file, 300) # Omitting second parameter will convert all sentences to JSON\n",
    "    \n",
    "    json.dump(doc, open(file[:-7] + '.json', 'w'), indent=4, separators=(',', ': '))\n",
    "    print(\"Parsed document: \",doc[\"_id\"], \"\\n Number of sentences parsed: \", len(doc[\"sentences\"]))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9957926d5dd50b60d41f14a85a3f4429983ca87c98bd0d55a66ff1af8959fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
