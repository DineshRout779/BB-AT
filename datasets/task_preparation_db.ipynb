{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Preparation and Inserion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import pymongo\n",
    "import bson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare connection to MongoDb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "databaseURL = \"mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&directConnection=true&ssl=false\"\n",
    "\n",
    "# production\n",
    "# databaseURL = \"mongodb+srv://behavannoserver:UsbThVH9VOIrOSBL@cluster0.k8tlu.mongodb.net/annotation?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(databaseURL)\n",
    "db = client[\"bbat\"]\n",
    "colExpt = db[\"experiments\"] # reference to collection \"experiments\"\n",
    "colTasks = db[\"tasks\"] # reference to collection \"tasks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get path of all treebank json files in datasets directory\n",
    "\n",
    "The root name is considered the name of the treebank. eg. UD_Afrikaans-AfriBooms is a treebank\n",
    "All the files inside that treebank are considered its documents. eg. The treebank UD_Afrikaans-AfriBooms contains three documents: af_afribooms-ud-dev, af_afribooms-ud-test, and af_afribooms-ud-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['treebanks/UD_Hindi-HDTB\\\\hi_hdtb-ud-dev.json',\n",
       " 'treebanks/UD_Hindi-HDTB\\\\hi_hdtb-ud-test.json',\n",
       " 'treebanks/UD_Hindi-HDTB\\\\hi_hdtb-ud-train.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files = glob.glob(\"**/*.json\", recursive=True) \n",
    "# remove ud_afrikaans later\n",
    "files = glob.glob(\"treebanks/UD_Hindi-HDTB/*.json\", recursive=True) \n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a key-value pair with treebank name as the key and its array of documents as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treebanks stored in dictionary:  UD_Hindi-HDTB\n"
     ]
    }
   ],
   "source": [
    "treebanks = {}\n",
    "\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "        treebank = data[\"dir\"][0]\n",
    "\n",
    "        if treebank in treebanks:\n",
    "            treebanks[treebank].append(data)\n",
    "        else:\n",
    "            treebanks[treebank] = [data]            \n",
    "\n",
    "print(\"Treebanks stored in dictionary: \", ', '.join(list(treebanks.keys())) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Function chunks(list, n) splits a list into smaller chunks containing n elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split list into sublist of equal parts of n and remainder\n",
    "def chunks(sents, n):\n",
    "    rem = len(sents) % n\n",
    "    for i in range(0,len(sents)-rem, n):\n",
    "        yield sents[i:i+n]\n",
    "    \n",
    "    if (rem != 0):\n",
    "        rest = sents[-rem:]\n",
    "        yield rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[7, 8, 9, 10, 11, 12, 13]\n",
      "[14, 15, 16, 17, 18, 19, 20]\n",
      "[21, 22, 23, 24, 25, 26, 27]\n",
      "[28, 29, 30, 31, 32, 33, 34]\n",
      "[35, 36, 37, 38, 39, 40, 41]\n",
      "[42, 43, 44, 45, 46, 47, 48]\n",
      "[49, 50, 51, 52, 53, 54, 55]\n",
      "[56, 57, 58, 59, 60, 61, 62]\n",
      "[63, 64, 65, 66, 67, 68, 69]\n",
      "[70, 71, 72, 73, 74, 75, 76]\n",
      "[77, 78, 79, 80, 81, 82, 83]\n",
      "[84, 85, 86, 87, 88, 89, 90]\n",
      "[91, 92, 93, 94, 95, 96, 97]\n",
      "[98]\n"
     ]
    }
   ],
   "source": [
    "# Example chunks fn\n",
    "a = list(range(99))\n",
    "for i in chunks(a, 7):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Task Preparation\n",
    "Each sentence in a treebank is prepared as an object containing information about it and stored in the array sents. <br>\n",
    "The sents array is then shuffled to randomize sentence order.<br> \n",
    "The sents array is then partitioned into tasks of size task_size(3) and relevant keys are attached to it<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks prepared:  223\n"
     ]
    }
   ],
   "source": [
    "task_size = 3 # Maximum number of sentences in each task\n",
    "\n",
    "tasks = []\n",
    "for treebank in treebanks:\n",
    "    \n",
    "    sents = []\n",
    "    for doc in treebanks[treebank]:\n",
    "        for sentence in doc[\"sentences\"]:\n",
    "            sent = {}\n",
    "            sent[\"file\"] = doc[\"_id\"] #\n",
    "            sent[\"sentId\"] = sentence[\"metadata\"][\"sent_id\"]\n",
    "            sent[\"text\"] = sentence[\"metadata\"][\"text\"]\n",
    "            sent[\"flag\"] = sentence[\"metadata\"][\"flag\"]\n",
    "            words = list(map(lambda x: x[\"form\"], sentence[\"token\"]))\n",
    "            sent[\"words\"] = words\n",
    "            sents.append(sent)\n",
    "\n",
    "    random.shuffle(sents) # remove to preserve sentence order\n",
    "    \n",
    "    #Partition sents into chunks for task\n",
    "    \n",
    "    for chunk in chunks(sents, task_size):\n",
    "        task = {}\n",
    "        task[\"sents\"] = chunk    \n",
    "        task[\"subjects\"] = []\n",
    "        task[\"adjudicators\"] = []\n",
    "        task[\"treebank\"] = treebank\n",
    "        tasks.append(task)\n",
    "        \n",
    "print(\"Number of tasks prepared: \", len(tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. (Optional) Uncomment and run to wipe all tasks and subject data\n",
    "#### Warning: permanently removes task data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 1098, 'ok': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# # DELETE!\n",
    "# query = {}\n",
    "# docs = colTasks.delete_many(query)\n",
    "# pprint.pprint(docs.raw_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Insert tasks into database\n",
    "Each task has to be associated with an experiment. Create an experiment in the tool and get the id from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 2 / 223"
     ]
    }
   ],
   "source": [
    "exptId=\"636f94c9693092cab0dcc169\" #example id\n",
    "\n",
    "# tasks[0:num] , where num is the number of tasks\n",
    "# you want to upload to database\n",
    "for i, task in enumerate(tasks[0:2]):\n",
    "    task[\"experiment\"] = bson.objectid.ObjectId(exptId)\n",
    "    result = colTasks.insert_one(task)\n",
    "    print(\"\\rUploaded\", i+1, \"/\" , len(tasks), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. (Optional) insert default UPOS tags to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('636f94c9693092cab0dcc169'), 'title': 'Default', 'experimenter': ObjectId('636f94c9693092cab0dcc168'), 'parameters': {'numShared': 2, 'numSharedAdju': 1, 'scaling': 'model', 'highlightBoundaries': [], 'highlights': [], 'matchMismatch': True, 'annConfidence': False, 'sentenceDiff': False}, 'subjects': [{'id': ObjectId('636f94df693092cab0dcc16e'), 'username': 'din_ann1', 'role': 'annotator'}, {'id': ObjectId('636f94ea693092cab0dcc175'), 'username': 'din_ann2', 'role': 'annotator'}, {'id': ObjectId('636f94f2693092cab0dcc17c'), 'username': 'din_adj', 'role': 'adjudicator'}], 'tags': [], '__v': 3}\n"
     ]
    }
   ],
   "source": [
    "tags = [\n",
    "\t{\n",
    "\t\t\"tag\":\"ADJ\",\n",
    "\t\t\"description\":\"adjective\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"ADP\",\n",
    "\t\t\"description\":\"adposition\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"ADV\",\n",
    "\t\t\"description\":\"adverb\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"AUX\",\n",
    "\t\t\"description\":\"auxiliary\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"CCONJ\",\n",
    "\t\t\"description\":\"coordinating conjunction\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"DET\",\n",
    "\t\t\"description\":\"determiner\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"INTJ\",\n",
    "\t\t\"description\":\"interjection\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"NOUN\",\n",
    "\t\t\"description\":\"noun\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"NUM\",\n",
    "\t\t\"description\":\"numeral\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"PART\",\n",
    "\t\t\"description\":\"particle\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"PRON\",\n",
    "\t\t\"description\":\"pronoun\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"PROPN\",\n",
    "\t\t\"description\":\"proper noun\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"PUNCT\",\n",
    "\t\t\"description\":\"punctuation\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"SCONJ\",\n",
    "\t\t\"description\":\"subordinating conjunction\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"SYM\",\n",
    "\t\t\"description\":\"symbol\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"VERB\",\n",
    "\t\t\"description\":\"verb\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"tag\":\"X\",\n",
    "\t\t\"description\":\"other\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "for i, tag in enumerate(tags):\n",
    "    tags[i][\"enabled\"] = True\n",
    "    \n",
    "result = colExpt.find_one_and_update(\n",
    "    {\"_id\": bson.objectid.ObjectId(exptId)},\n",
    "    {'$set' : {'tags': tags}}\n",
    ")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9957926d5dd50b60d41f14a85a3f4429983ca87c98bd0d55a66ff1af8959fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
